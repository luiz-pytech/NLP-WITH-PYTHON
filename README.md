# NLP WITH PYTHON: Challenges and Studies

## ğŸ“– About The Project

This repository was created as a practical study project to consolidate the knowledge acquired in a **Natural Language Processing (NLP)** course, inspired by the DataCamp learning track. The goal is to practically apply the main techniques and tools of the NLP ecosystem in Python, from fundamental text manipulation to the implementation of advanced models with the Hugging Face `transformers` library.

Each folder corresponds to a chapter of the course and contains notebooks with challenging exercises designed to reinforce theoretical learning with real-world implementation.

---

## ğŸš€ Topics Covered

The journey through this repository covers the essential pillars of Natural Language Processing:

1.  **Fundamentals of Text Processing:** Text preparation and cleaning techniques, including tokenization, stopword removal, normalization (lowercasing), stemming, and lemmatization.

2.  **Feature Extraction:** Methods for transforming text into numerical representations that Machine Learning models can understand, such as **Bag-of-Words (BoW)**, **TF-IDF**, and the exploration of **Word Embeddings** (Word2Vec, GloVe).

3.  **Text Classification with Hugging Face:** Leveraging the power of pre-trained models (*transformers*) for advanced tasks such as **Sentiment Analysis**, **Zero-Shot Classification**, semantic similarity checking, and grammar correction.

4.  **Token Classification and Text Generation:** Modern applications such as **Named Entity Recognition (NER)**, Part-of-Speech (PoS) tagging, **automatic summarization**, **translation**, and **text generation**, also using Hugging Face pipelines.

---
## ğŸ“Š Dataset Used

For the exploration and development of the notebooks in this project, the **Olist Public E-commerce Dataset** was used.

This is a real, anonymized dataset containing information on over 100,000 orders placed at various marketplaces in Brazil between 2016 and 2018. The richness of its textual data, such as customer reviews and product descriptions, makes it an ideal dataset for Natural Language Processing (NLP) studies and applications.

â¡ï¸ **Link to the dataset:** [Brazilian E-Commerce Public Dataset by Olist on Kaggle](https://www.kaggle.com/datasets/olistbr/brazilian-ecommerce)

---
## ğŸ“‚ Repository Structure

The project is organized into directories, with each one corresponding to a study module:
```
/NLP_WITH_PYTHON
â”œâ”€â”€ 01_fundamentals_and_words_processing/
â”‚   â”œâ”€â”€ 01_tokenization.ipynb
â”‚   â”œâ”€â”€ 02_cleaning_and_normalization.ipynb
â”‚   â””â”€â”€ 03_stemming_and_lemmatization.ipynb
â”œâ”€â”€ 02_feature_extraction/
â”‚   â”œâ”€â”€ 01_bag_of_words.ipynb
â”‚   â”œâ”€â”€ 02_TF_IDF.ipynb
â”‚   â””â”€â”€ 03_words_embeddings.ipynb
â”œâ”€â”€ 03_classification_with_HuggingFace/
â”‚   â”œâ”€â”€ 01_sentimental_analysis.ipynb
â”‚   â”œâ”€â”€ 02_zero_shot_classification.ipynb
â”‚   â””â”€â”€ 03_similarity_and_grammar.ipynb
â”œâ”€â”€ 04_tokens_and_text_generation/
â”‚   â”œâ”€â”€ 01_recognition_of_named_entity_NER.ipynb
â”‚   â”œâ”€â”€ 02_text_summary.ipynb
â”‚   â”œâ”€â”€ 03_automatic_translation.ipynb
â”‚   â””â”€â”€ 04_simple_autocomplete_system.ipynb
â”œâ”€â”€ README.md
â””â”€â”€ requirements.txt
```
---

## ğŸ› ï¸ Technologies and Libraries

This project was developed using **Python 3** and the following main libraries:

* **Jupyter Notebook:** For creating the exercises interactively.
* **Pandas:** For data manipulation and analysis.
* **NLTK (Natural Language Toolkit):** For fundamental tasks like tokenization and stemming.
* **spaCy:** For efficient text processing, especially for lemmatization and NER.
* **Scikit-learn:** For Bag-of-Words and TF-IDF implementations.
* **Hugging Face `transformers`:** For using state-of-the-art models in classification, generation, and other tasks.
* **Matplotlib & Seaborn:** For data visualization, such as word frequencies.

---

## ğŸ“Š Datasets

The exercises primarily use public datasets of text in Portuguese, with a focus on product reviews. An excellent data source used is the [Brazilian E-Commerce Public Dataset by Olist](https://www.kaggle.com/datasets/olistbr/brazilian-ecommerce), available on Kaggle.

---

## ğŸš€ How to Use

To explore this repository:

1.  **Clone the repository:**
    ```bash
    git clone [https://github.com/SEU-USUARIO/NLP_WITH_PYTHON.git](https://github.com/SEU-USUARIO/NLP_WITH_PYTHON.git)
    ```

2.  **Navigate to the directory:**
    ```bash
    cd NLP_WITH_PYTHON
    ```

3.  **Install the dependencies:**
    (It is recommended to create a virtual environment first)
    ```bash
    pip install -r requirements.txt
    ```

4.  **Explore the notebooks:** Open the notebooks in each folder to see the challenges and my solutions. Feel free to run the code and experiment with your own texts!

---
*frequency_words.ipynb is the resolution question of data science IMD for analysis sentimentals*

## âœï¸ Author

* **LUIZ FELIPE**

---
